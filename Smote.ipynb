{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164c585f-94b1-47d4-bfa9-f4bde1e89703",
   "metadata": {},
   "source": [
    "# Fraud Detection Model Improvement\n",
    "\n",
    "## 2. Use Resampling Techniques\n",
    "\n",
    "Fraud detection is highly imbalanced, and resampling can help address this without needing a new model.\n",
    "\n",
    "### Method: Apply SMOTE\n",
    "- **Synthetic Minority Over-sampling Technique (SMOTE)**: This method increases the representation of fraud cases in the training data or undersamples the majority class.\n",
    "\n",
    "### Tools\n",
    "- Libraries like `imblearn` provide easy-to-implement SMOTE.\n",
    "\n",
    "### Goal\n",
    "- Improve recall without excessively sacrificing precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5909db-6d32-42d8-af61-c307aa825f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv(r'C:\\Users\\Zana\\Desktop\\portfolio_projects\\project_8\\fraudData_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676f6c80-bbef-4a65-8ef7-6cd228e99f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867244   \n",
      "1           1   2020-06-21 12:14:33  3573030041201292   \n",
      "2           2   2020-06-21 12:14:53  3598215285024754   \n",
      "3           3   2020-06-21 12:15:15  3591919803438423   \n",
      "4           4   2020-06-21 12:15:17  3526826139003047   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street  ...  \\\n",
      "0   Elliott      M            351 Darlene Green  ...   \n",
      "1  Williams      F             3638 Marsh Union  ...   \n",
      "2     Lopez      F         9333 Valentine Point  ...   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  ...   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465  ...   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud  transaction_hour transaction_dayofweek transaction_day  \\\n",
      "0         0                12                     6              21   \n",
      "1         0                12                     6              21   \n",
      "2         0                12                     6              21   \n",
      "3         0                12                     6              21   \n",
      "4         0                12                     6              21   \n",
      "\n",
      "  transaction_month  age  \n",
      "0                 6   52  \n",
      "1                 6   30  \n",
      "2                 6   50  \n",
      "3                 6   33  \n",
      "4                 6   65  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe for processing\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbde3d-f865-44be-9889-9a011ae24f66",
   "metadata": {},
   "source": [
    "Step 1: Prepare the Data for SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de760b9-792f-475f-b34b-8b08a041a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         category    amt gender state      lat      long  city_pop  \\\n",
      "0   personal_care   2.86      M    SC  33.9659  -80.9355    333497   \n",
      "1   personal_care  29.84      F    UT  40.3207 -110.4360       302   \n",
      "2  health_fitness  41.28      F    NY  40.6729  -73.5365     34496   \n",
      "3        misc_pos  60.05      M    FL  28.5697  -80.8191     54767   \n",
      "4          travel   3.19      M    MI  44.2529  -85.0170      1126   \n",
      "\n",
      "          dob   unix_time  merch_lat  merch_long  is_fraud  transaction_hour  \\\n",
      "0  1968-03-19  1371816865  33.986391  -81.200714         0                12   \n",
      "1  1990-01-17  1371816873  39.450498 -109.960431         0                12   \n",
      "2  1970-10-21  1371816893  40.495810  -74.196111         0                12   \n",
      "3  1987-07-25  1371816915  28.812398  -80.883061         0                12   \n",
      "4  1955-07-06  1371816917  44.959148  -85.884734         0                12   \n",
      "\n",
      "   transaction_dayofweek  transaction_day  transaction_month  age  \n",
      "0                      6               21                  6   52  \n",
      "1                      6               21                  6   30  \n",
      "2                      6               21                  6   50  \n",
      "3                      6               21                  6   33  \n",
      "4                      6               21                  6   65  \n",
      "Index(['category', 'amt', 'gender', 'state', 'lat', 'long', 'city_pop', 'dob',\n",
      "       'unix_time', 'merch_lat', 'merch_long', 'is_fraud', 'transaction_hour',\n",
      "       'transaction_dayofweek', 'transaction_day', 'transaction_month', 'age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns from the copy\n",
    "columns_to_drop = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'zip', 'job', 'trans_num']\n",
    "df_copy = df_copy.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the updated dataframe's first few rows and columns\n",
    "print(df_copy.head())\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d4e5e-c503-440c-94a1-32e0c5011228",
   "metadata": {},
   "source": [
    "Step 2: Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b7d0ec-13d7-4876-a882-12348be3c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     amt  gender      lat      long  city_pop         dob   unix_time  \\\n",
      "0   2.86       1  33.9659  -80.9355    333497  1968-03-19  1371816865   \n",
      "1  29.84       0  40.3207 -110.4360       302  1990-01-17  1371816873   \n",
      "2  41.28       0  40.6729  -73.5365     34496  1970-10-21  1371816893   \n",
      "3  60.05       1  28.5697  -80.8191     54767  1987-07-25  1371816915   \n",
      "4   3.19       1  44.2529  -85.0170      1126  1955-07-06  1371816917   \n",
      "\n",
      "   merch_lat  merch_long  is_fraud  ...  state_SD  state_TN  state_TX  \\\n",
      "0  33.986391  -81.200714         0  ...     False     False     False   \n",
      "1  39.450498 -109.960431         0  ...     False     False     False   \n",
      "2  40.495810  -74.196111         0  ...     False     False     False   \n",
      "3  28.812398  -80.883061         0  ...     False     False     False   \n",
      "4  44.959148  -85.884734         0  ...     False     False     False   \n",
      "\n",
      "   state_UT  state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \n",
      "0     False     False     False     False     False     False     False  \n",
      "1      True     False     False     False     False     False     False  \n",
      "2     False     False     False     False     False     False     False  \n",
      "3     False     False     False     False     False     False     False  \n",
      "4     False     False     False     False     False     False     False  \n",
      "\n",
      "[5 rows x 77 columns]\n",
      "Index(['amt', 'gender', 'lat', 'long', 'city_pop', 'dob', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud', 'transaction_hour',\n",
      "       'transaction_dayofweek', 'transaction_day', 'transaction_month', 'age',\n",
      "       'category_food_dining', 'category_gas_transport',\n",
      "       'category_grocery_net', 'category_grocery_pos',\n",
      "       'category_health_fitness', 'category_home', 'category_kids_pets',\n",
      "       'category_misc_net', 'category_misc_pos', 'category_personal_care',\n",
      "       'category_shopping_net', 'category_shopping_pos', 'category_travel',\n",
      "       'state_AL', 'state_AR', 'state_AZ', 'state_CA', 'state_CO', 'state_CT',\n",
      "       'state_DC', 'state_FL', 'state_GA', 'state_HI', 'state_IA', 'state_ID',\n",
      "       'state_IL', 'state_IN', 'state_KS', 'state_KY', 'state_LA', 'state_MA',\n",
      "       'state_MD', 'state_ME', 'state_MI', 'state_MN', 'state_MO', 'state_MS',\n",
      "       'state_MT', 'state_NC', 'state_ND', 'state_NE', 'state_NH', 'state_NJ',\n",
      "       'state_NM', 'state_NV', 'state_NY', 'state_OH', 'state_OK', 'state_OR',\n",
      "       'state_PA', 'state_RI', 'state_SC', 'state_SD', 'state_TN', 'state_TX',\n",
      "       'state_UT', 'state_VA', 'state_VT', 'state_WA', 'state_WI', 'state_WV',\n",
      "       'state_WY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Encode 'gender' column\n",
    "df_copy['gender'] = df_copy['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# One-hot encoding for 'category' and 'state' columns\n",
    "df_copy = pd.get_dummies(df_copy, columns=['category', 'state'], drop_first=True)\n",
    "\n",
    "# Display the updated dataframe's first few rows\n",
    "print(df_copy.head())\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88aa94c-be05-4c3d-92cb-88a4f5320713",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'zip', 'job', 'trans_num'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Data Preparation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Drop unnecessary columns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrans_date_trans_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcc_num\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerchant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrans_num\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdob\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m df_copy \u001b[38;5;241m=\u001b[39m df_copy\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure all columns are numeric\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert 'gender' to binary (M=1, F=0)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pymc_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'zip', 'job', 'trans_num'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Step 2: Data Preparation\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'zip', 'job', 'trans_num', 'dob']\n",
    "df_copy = df_copy.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "# Convert 'gender' to binary (M=1, F=0)\n",
    "df_copy['gender'] = df_copy['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# One-hot encoding for categorical features like 'category' and 'state'\n",
    "df_copy = pd.get_dummies(df_copy, columns=['category', 'state'], drop_first=True)\n",
    "\n",
    "# Display the updated dataframe's first few rows and columns\n",
    "print(df_copy.head())\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa24584f-eb23-46d4-992d-185212e19629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['amt', 'gender', 'lat', 'long', 'city_pop', 'dob', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud', 'transaction_hour',\n",
      "       'transaction_dayofweek', 'transaction_day', 'transaction_month', 'age',\n",
      "       'category_food_dining', 'category_gas_transport',\n",
      "       'category_grocery_net', 'category_grocery_pos',\n",
      "       'category_health_fitness', 'category_home', 'category_kids_pets',\n",
      "       'category_misc_net', 'category_misc_pos', 'category_personal_care',\n",
      "       'category_shopping_net', 'category_shopping_pos', 'category_travel',\n",
      "       'state_AL', 'state_AR', 'state_AZ', 'state_CA', 'state_CO', 'state_CT',\n",
      "       'state_DC', 'state_FL', 'state_GA', 'state_HI', 'state_IA', 'state_ID',\n",
      "       'state_IL', 'state_IN', 'state_KS', 'state_KY', 'state_LA', 'state_MA',\n",
      "       'state_MD', 'state_ME', 'state_MI', 'state_MN', 'state_MO', 'state_MS',\n",
      "       'state_MT', 'state_NC', 'state_ND', 'state_NE', 'state_NH', 'state_NJ',\n",
      "       'state_NM', 'state_NV', 'state_NY', 'state_OH', 'state_OK', 'state_OR',\n",
      "       'state_PA', 'state_RI', 'state_SC', 'state_SD', 'state_TN', 'state_TX',\n",
      "       'state_UT', 'state_VA', 'state_VT', 'state_WA', 'state_WI', 'state_WV',\n",
      "       'state_WY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the current columns in df_copy\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "036f7be6-cc6d-4699-a5a5-9e3cc1ca3bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amt         float64\n",
      "gender        int64\n",
      "lat         float64\n",
      "long        float64\n",
      "city_pop      int64\n",
      "             ...   \n",
      "state_VT       bool\n",
      "state_WA       bool\n",
      "state_WI       bool\n",
      "state_WV       bool\n",
      "state_WY       bool\n",
      "Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the columns in df_copy\n",
    "print(df_copy.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f577a3-cfd9-4bed-a49a-dca878af7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     amt  gender      lat      long  city_pop   unix_time  merch_lat  \\\n",
      "0   2.86       1  33.9659  -80.9355    333497  1371816865  33.986391   \n",
      "1  29.84       0  40.3207 -110.4360       302  1371816873  39.450498   \n",
      "2  41.28       0  40.6729  -73.5365     34496  1371816893  40.495810   \n",
      "3  60.05       1  28.5697  -80.8191     54767  1371816915  28.812398   \n",
      "4   3.19       1  44.2529  -85.0170      1126  1371816917  44.959148   \n",
      "\n",
      "   merch_long  is_fraud  transaction_hour  ...  state_SD  state_TN  state_TX  \\\n",
      "0  -81.200714         0                12  ...     False     False     False   \n",
      "1 -109.960431         0                12  ...     False     False     False   \n",
      "2  -74.196111         0                12  ...     False     False     False   \n",
      "3  -80.883061         0                12  ...     False     False     False   \n",
      "4  -85.884734         0                12  ...     False     False     False   \n",
      "\n",
      "   state_UT  state_VA  state_VT  state_WA  state_WI  state_WV  state_WY  \n",
      "0     False     False     False     False     False     False     False  \n",
      "1      True     False     False     False     False     False     False  \n",
      "2     False     False     False     False     False     False     False  \n",
      "3     False     False     False     False     False     False     False  \n",
      "4     False     False     False     False     False     False     False  \n",
      "\n",
      "[5 rows x 76 columns]\n",
      "amt         float64\n",
      "gender        int64\n",
      "lat         float64\n",
      "long        float64\n",
      "city_pop      int64\n",
      "             ...   \n",
      "state_VT       bool\n",
      "state_WA       bool\n",
      "state_WI       bool\n",
      "state_WV       bool\n",
      "state_WY       bool\n",
      "Length: 76, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'dob' column since we already have 'age'\n",
    "df_copy = df_copy.drop(columns=['dob'])\n",
    "\n",
    "# Check the updated dataframe\n",
    "print(df_copy.head())\n",
    "print(df_copy.dtypes)  # Verify the data types again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf780be-d091-461b-a497-c4b67b311756",
   "metadata": {},
   "source": [
    "Step 3: Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfd9ca0-d635-47f1-9861-95f8af22c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set shape: is_fraud\n",
      "0    387502\n",
      "1      1501\n",
      "Name: count, dtype: int64\n",
      "Resampled training set shape: is_fraud\n",
      "0    387502\n",
      "1    387502\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_copy.drop(columns=['is_fraud'])  # Features\n",
    "y = df_copy['is_fraud']                  # Target variable\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(\"Original training set shape:\", y_train.value_counts())\n",
    "print(\"Resampled training set shape:\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcc110-9d40-4863-b289-45fbf3eb6a0d",
   "metadata": {},
   "source": [
    "Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ec2bd7-1831-40af-a437-5fa665f26e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[158409   7663]\n",
      " [   151    493]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98    166072\n",
      "           1       0.06      0.77      0.11       644\n",
      "\n",
      "    accuracy                           0.95    166716\n",
      "   macro avg       0.53      0.86      0.54    166716\n",
      "weighted avg       1.00      0.95      0.97    166716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model with the resampled training data\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1fc99-5590-44fa-b8cb-173b9e3473d4",
   "metadata": {},
   "source": [
    "Step 5: Save SMOTE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9116539-ca0d-4e48-bb8c-f69d15d4ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SMOTE results\n",
    "smote_results = pd.DataFrame({\n",
    "    'Original Class Distribution': y_train.value_counts(),\n",
    "    'Resampled Class Distribution': y_train_resampled.value_counts()\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "smote_results.to_csv(r'C:\\Users\\Zana\\Desktop\\portfolio_projects\\project_8\\smote_results.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcad91-8bb6-466d-8a38-0b488827a1c0",
   "metadata": {},
   "source": [
    "## SMOTE Results\n",
    "\n",
    "### Original Class Distribution\n",
    "- **Number of Non-Fraud Cases (0)**: 387,502\n",
    "- **Number of Fraud Cases (1)**: 1,501\n",
    "\n",
    "### Resampled Class Distribution\n",
    "- **Number of Non-Fraud Cases (0)**: 387,502\n",
    "- **Number of Fraud Cases (1)**: 387,502\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59840fc-61ae-4552-bcbe-0a34406cdf66",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589d916-c239-47ac-842d-2f27bef22455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
